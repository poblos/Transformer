{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4215,
     "status": "ok",
     "timestamp": 1707081479963,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "9XR6Di4ILdb8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Tuple, Any, Optional\n",
    "\n",
    "HiddenT = torch.tensor  # torch tensor of shape [BATCH, SEQ_LEN, HIDDEN_DIM]\n",
    "\n",
    "\n",
    "class FeedForward(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Inputs a tensor of shape [BATCH, SEQ_LEN, HIDDEN_DIM]\n",
    "    and processes it as follows:\n",
    "    * project linearly from hidden_dim to inner_dim\n",
    "    * apply activation function (GELU)\n",
    "    * project linearly from inner_dim to hidden_dim\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim: int, inner_dim: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(hidden_dim, inner_dim)\n",
    "        self.activation = torch.nn.GELU()\n",
    "        self.linear2 = torch.nn.Linear(inner_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x: HiddenT) -> HiddenT:\n",
    "        # [BATCH, SEQ_LEN, HIDDEN_DIM]\n",
    "        assert len(x.shape) == 3\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        result = self.linear2(x)\n",
    "\n",
    "        # [BATCH, SEQ_LEN, HIDDEN_DIM]\n",
    "        assert len(result.shape) == 3\n",
    "        return result\n",
    "\n",
    "\n",
    "##### TESTS START #####\n",
    "\n",
    "def test_ff():\n",
    "    def test_grad_and_shapes():\n",
    "        feed_forward = FeedForward(16, 32)\n",
    "        assert len(list(feed_forward.parameters())) >= 1\n",
    "        x = torch.rand(3, 5, 16, requires_grad=True)\n",
    "        y = feed_forward(x)\n",
    "        assert x.shape == y.shape\n",
    "        loss = y.sum()\n",
    "        loss.backward()\n",
    "        assert x.grad is not None\n",
    "\n",
    "    test_grad_and_shapes()\n",
    "\n",
    "\n",
    "test_ff()\n",
    "\n",
    "#####  TESTS END  #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707081479964,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "K5z090XMLdb9"
   },
   "outputs": [],
   "source": [
    "AttentionT = torch.tensor  # torch tensor of shape [BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM]\n",
    "\n",
    "\n",
    "class AttentionCreateQKV(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Given a tensor of shape [BATCH, SEQ_LEN, HIDDEN_DIM]\n",
    "    uses linear projections to create three tensors\n",
    "    Query, Key and Value.\n",
    "    Each of the created tensors has shape [BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM].\n",
    "    Where HEAD_DIM = HIDDEN_DIM // NUM_HEADS\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim, num_heads) -> None:\n",
    "        super().__init__()\n",
    "        assert hidden_dim % num_heads == 0\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.query_linear = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key_linear = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value_linear = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x: HiddenT) -> Tuple[AttentionT, AttentionT, AttentionT]:\n",
    "        assert len(x.shape) == 3  # torch tensor of shape [BATCH, SEQ_LEN, HIDDEN_DIM]\n",
    "\n",
    "        BATCH = x.size(0)\n",
    "        SEQ_LEN = x.size(1)\n",
    "\n",
    "        Q = self.query_linear(x)\n",
    "        Q = Q.view(BATCH, SEQ_LEN, self.num_heads, self.head_dim)\n",
    "\n",
    "        K = self.key_linear(x)\n",
    "        K = K.view(BATCH, SEQ_LEN, self.num_heads, self.head_dim)\n",
    "\n",
    "        V = self.value_linear(x)\n",
    "        V = V.view(BATCH, SEQ_LEN, self.num_heads, self.head_dim)\n",
    "\n",
    "        result = [Q, K, V]\n",
    "\n",
    "        assert len(result) == 3  # queries, keys, values\n",
    "        for r in result:\n",
    "            assert len(r.shape) == 4  # [BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM]\n",
    "            assert r.shape[-2:] == (self.num_heads, self.head_dim)\n",
    "            assert r.shape[:-2] == x.shape[:2]\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "##### TESTS START #####\n",
    "\n",
    "def test_attn_create_qkv():\n",
    "    def test_shapes():\n",
    "        hidden_dim = 16\n",
    "        num_heads = 8\n",
    "        l = AttentionCreateQKV(hidden_dim=hidden_dim, num_heads=num_heads)\n",
    "        x = torch.ones(3, 5, hidden_dim)\n",
    "        ys = l(x)\n",
    "        assert len(ys) == 3\n",
    "        for y in ys:\n",
    "            assert y.shape == x.shape[:-1] + (num_heads, hidden_dim // num_heads)\n",
    "\n",
    "    test_shapes()\n",
    "\n",
    "test_attn_create_qkv()\n",
    "\n",
    "#####  TESTS END  #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707081479964,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "mg_3YqkwLdb-"
   },
   "outputs": [],
   "source": [
    "class RoPEPosEncoding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Given a tensor of shape [BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM]\n",
    "    applies Rotary Positional Encoding.\n",
    "    offset allows to apply rotary to sequnce part by part by telling how much tokens preecede the input in the sequence.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, head_dim, theta) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        assert head_dim % 2 == 0\n",
    "        self.hidden_dim = head_dim\n",
    "\n",
    "        self.theta = theta\n",
    "        self.register_buffer(\"angles\", torch.pow(1 / self.theta, 2 * torch.arange(self.hidden_dim // 2).float() / self.hidden_dim))\n",
    "\n",
    "    def forward(self, x: AttentionT, offset: int = 0):\n",
    "        assert (\n",
    "            len(x.shape) == 4\n",
    "        )  # torch tensor of shape [BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM]\n",
    "        assert offset >= 0\n",
    "\n",
    "        BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM = x.shape\n",
    "\n",
    "        position_indices = torch.arange(SEQ_LEN, device=x.device).unsqueeze(1)\n",
    "        angles = self.angles * (position_indices + offset)  # torch tensor of shape [SEQ_LEN, HEAD_DIM // 2]\n",
    "\n",
    "        sines = torch.sin(angles)\n",
    "        cosines = torch.cos(angles)\n",
    "        x_paired = x.view(BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM // 2, 2)\n",
    "\n",
    "        cosines = cosines.view(1, SEQ_LEN, 1, HEAD_DIM // 2)\n",
    "        sines = sines.view(1, SEQ_LEN, 1, HEAD_DIM // 2)\n",
    "\n",
    "        x_rotated_fst = cosines * x_paired[..., 0] - sines * x_paired[..., 1]\n",
    "        x_rotated_snd = sines * x_paired[..., 0] + cosines * x_paired[..., 1]\n",
    "\n",
    "        result = torch.stack([x_rotated_fst, x_rotated_snd], dim=-1)\n",
    "\n",
    "        result = result.view(BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM)\n",
    "\n",
    "        assert result.shape == x.shape\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "##### TESTS START #####\n",
    "\n",
    "def test_RoPE():\n",
    "    def test_offset():\n",
    "        rope = RoPEPosEncoding(16, 10000)\n",
    "        x = torch.ones(1, 11, 3, 16)\n",
    "        y = rope(x, offset=0)\n",
    "        z = rope(x, offset=2)\n",
    "\n",
    "        assert (torch.abs(z[:, :-2] - y[:, 2:])).sum() <= 1e-4\n",
    "        assert (torch.abs(z[:, :2] - y[:, :2])).sum() >= 1e-4\n",
    "\n",
    "    def test_initial_rotation():\n",
    "        rope = RoPEPosEncoding(16, 10000)\n",
    "        x = torch.ones(1, 11, 3, 16)\n",
    "        y = rope(x, offset=0)\n",
    "\n",
    "        assert (torch.abs(y[:, 0] - x[:, 0])).sum() <= 1e-4\n",
    "\n",
    "    test_offset()\n",
    "    test_initial_rotation()\n",
    "\n",
    "test_RoPE()\n",
    "\n",
    "#####  TESTS END  #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707081479965,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "71sUZ9GyLdb_"
   },
   "outputs": [],
   "source": [
    "ACacheT = Tuple[\n",
    "    torch.tensor, torch.tensor\n",
    "]  # key, value, both of shape [BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM]\n",
    "\n",
    "import math\n",
    "class Attention(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implements multi-head attention layer.\n",
    "    Inputs tensor x of shape [BATCH, SEQ_LEN, hidden_dim].\n",
    "    Uses head_proj to create three tensors q, k, v - each of shape\n",
    "    [BATCH, SEQ_LEN, num_heads, head_dim].\n",
    "    Then applies RoPE to q and k.\n",
    "    Then calculates attention within each head, concatenates the results\n",
    "    and linearly projects them to a tensor of shape [BATCH, SEQ_LEN, hidden_dim].\n",
    "\n",
    "    Cache is a tuple of keys (kc) and values (vc) calculated in previous calls.\n",
    "    For training the cache will be empty (tensors kc and vc should have shape [BATCH, 0, num_heads, hidden_dim]),\n",
    "    For efficient generation, the cache will contain keys (kc), values (vc) of already read/generated tokens\n",
    "    (this allows the generation of one additional token without recomputing the keys and values for all preceding tokens).\n",
    "    After RoPE application to k, kc and vc are prepended to k and v respectively.\n",
    "\n",
    "    The model outputs the linearly projected output of attention along with a cache extended with new keys and values.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, hidden_dim: int, num_heads: int, head_proj=AttentionCreateQKV\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        assert hidden_dim % num_heads == 0\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "\n",
    "        self.head_proj = head_proj(hidden_dim, num_heads)\n",
    "        self.q_rope = RoPEPosEncoding(self.head_dim, 10000)\n",
    "        self.k_rope = RoPEPosEncoding(self.head_dim, 10000)\n",
    "        self.out_proj = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def get_empty_cache(self, batch_size: int, device) -> ACacheT:\n",
    "        return torch.empty(\n",
    "            batch_size, 0, self.num_heads, self.head_dim, device=device\n",
    "        ), torch.empty(batch_size, 0, self.num_heads, self.head_dim, device=device)\n",
    "\n",
    "    def forward(self, x: HiddenT, cache: ACacheT) -> HiddenT:\n",
    "        assert len(x.shape) == 3  # torch tensor of shape [BATCH, SEQ_LEN, HIDDEN_DIM]\n",
    "\n",
    "        BATCH, SEQ_LEN, HIDDEN_DIM = x.size()\n",
    "\n",
    "        Q,K,V = self.head_proj(x)\n",
    "        Q = Q.view(BATCH, SEQ_LEN, self.num_heads, self.head_dim)\n",
    "        K = K.view(BATCH, SEQ_LEN, self.num_heads, self.head_dim)\n",
    "        V = V.view(BATCH, SEQ_LEN, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.k_rope(K).transpose(1, 2)\n",
    "        Q = self.q_rope(Q).transpose(1, 2)\n",
    "\n",
    "        attention_scores = torch.matmul(Q, K.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "\n",
    "        mask = torch.tril(torch.ones(SEQ_LEN, SEQ_LEN, device=x.device), diagonal=0).bool()\n",
    "        attention_scores.masked_fill_(~mask, float('-inf'))\n",
    "\n",
    "        attention_weights = torch.nn.functional.softmax(attention_scores, dim=-1)\n",
    "        attention_output = torch.matmul(attention_weights, V)\n",
    "\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(BATCH, SEQ_LEN, -1)\n",
    "        attention = self.out_proj(attention_output)\n",
    "\n",
    "        return attention, attention_weights, cache\n",
    "\n",
    "\n",
    "def test_attention():\n",
    "    def test_shapes():\n",
    "        num_heads = 8\n",
    "        hidden_dim = 16\n",
    "        attn_layer = Attention(hidden_dim, num_heads)\n",
    "        x = torch.ones(2, 5, hidden_dim)\n",
    "        y, attn_w, _ = attn_layer(\n",
    "            x, attn_layer.get_empty_cache(2, torch.device(\"cpu\"))\n",
    "        )\n",
    "\n",
    "        assert y.shape == x.shape\n",
    "        assert attn_w.shape == y.shape[:-2] + (num_heads, y.shape[-2], y.shape[-2])\n",
    "\n",
    "    def test_attention_masking():\n",
    "        num_heads = 8\n",
    "        hidden_dim = 16\n",
    "        attn_layer = Attention(hidden_dim, num_heads)\n",
    "        x = torch.ones(2, 5, hidden_dim)\n",
    "        y, attn_w, cache = attn_layer(\n",
    "            x, attn_layer.get_empty_cache(2, torch.device(\"cpu\"))\n",
    "        )\n",
    "\n",
    "        assert (attn_w < 0).sum() <= 1e-4\n",
    "\n",
    "        assert (torch.triu(torch.ones(5, 5), diagonal=1) * attn_w).sum() <= 1e-4\n",
    "\n",
    "    test_shapes()\n",
    "    test_attention_masking()\n",
    "\n",
    "\n",
    "test_attention()\n",
    "\n",
    "#####  TESTS END  #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1895,
     "status": "ok",
     "timestamp": 1707081481855,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "LhmWyhw8LdcB"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, eps=1e-05) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.eps = eps\n",
    "\n",
    "        self.gamma = torch.nn.Parameter(torch.ones(hidden_dim))\n",
    "        self.beta = torch.nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "    def forward(self, x: HiddenT) -> HiddenT:\n",
    "        assert len(x.shape) == 3  # torch tensor of shape [BATCH, SEQ_LEN, HIDDEN_DIM]\n",
    "\n",
    "        mean = torch.mean(x,-1).unsqueeze(-1)\n",
    "        dev = torch.sqrt(torch.var(x,-1, unbiased=False) + self.eps).unsqueeze(-1)\n",
    "\n",
    "        result = (x - mean) / dev * self.gamma + self.beta\n",
    "\n",
    "        assert x.shape == result.shape\n",
    "        return result\n",
    "\n",
    "\n",
    "##### TESTS START #####\n",
    "\n",
    "def test_layer_norm():\n",
    "\n",
    "    @torch.no_grad\n",
    "    def test_initial_norm():\n",
    "        ln = LayerNorm(16)\n",
    "        x = torch.rand((3, 5, 16))\n",
    "        normalized = ln(x)\n",
    "        assert torch.abs(torch.mean(normalized, dim=-1)).mean()  <= 1e-4\n",
    "        assert torch.abs(torch.std(normalized, dim=-1, unbiased=False).mean() - 1) <= 1e-2\n",
    "\n",
    "\n",
    "    def test_rising_norm():\n",
    "        ln = LayerNorm(16)\n",
    "        x = torch.rand((3, 5, 16))\n",
    "        initial_norm = torch.sqrt((ln(x) ** 2).sum(dim=-1))\n",
    "\n",
    "        optim = torch.optim.AdamW(ln.parameters(), lr=10)\n",
    "\n",
    "        for i in range(100):\n",
    "            optim.zero_grad()\n",
    "            norm = torch.sqrt((ln(x) ** 2).sum(dim=-1))\n",
    "            loss = -norm.mean()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "        final_norm = torch.sqrt((ln(x) ** 2).sum(dim=-1))\n",
    "        assert final_norm.mean() - initial_norm.mean() > 100.0\n",
    "\n",
    "\n",
    "    test_initial_norm()\n",
    "    test_rising_norm()\n",
    "\n",
    "test_layer_norm()\n",
    "\n",
    "#####  TESTS END  #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1707081481856,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "0nlaIGbbLdcB"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, ff_dim, num_heads) -> None:\n",
    "        \"\"\"\n",
    "        ff_dim - internal dimension of feed_forward.\n",
    "        num_heads - num attention heads\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.norm1 = LayerNorm(hidden_dim)\n",
    "        self.attention = Attention(hidden_dim, num_heads)\n",
    "        self.norm2 = LayerNorm(hidden_dim)\n",
    "        self.feed_forward = FeedForward(hidden_dim, ff_dim)\n",
    "\n",
    "    def get_empty_cache(self, batch_size: int, device):\n",
    "        return self.attention.get_empty_cache(batch_size=batch_size, device=device)\n",
    "\n",
    "    def forward(self, x: HiddenT, attn_cache: ACacheT) -> Tuple[HiddenT, ACacheT]:\n",
    "        y = self.norm1(x)\n",
    "        y,_, _ = self.attention(y, None)\n",
    "        y = y + x\n",
    "        z = self.norm2(y)\n",
    "        z = self.feed_forward(z)\n",
    "        result =  z + y\n",
    "        cache = None\n",
    "\n",
    "        assert x.shape == result.shape\n",
    "\n",
    "        return result, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707081481856,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "jiKHrnTrLdcC"
   },
   "outputs": [],
   "source": [
    "\n",
    "TokensT = torch.tensor # [BATCH, SEQ_LEN]\n",
    "ModelLT = torch.tensor # [BATCH, SEQ_LEN, VOCAB_SIZE]\n",
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, vocab_size: int, n_layers: int, hidden_dim: int, ff_dim: int, num_heads: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, hidden_dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList([\n",
    "            TransformerBlock(hidden_dim=hidden_dim, ff_dim=ff_dim, num_heads=num_heads) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        self.final_proj = torch.nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x: TokensT, cache : Optional[List[ACacheT]] = None) -> Tuple[ModelLT, List[ACacheT]]:\n",
    "        assert len(x.shape) == 2 # [BATCH, SEQ_LEN]\n",
    "        assert cache is None or len(cache) == self.n_layers\n",
    "\n",
    "        if cache is None:\n",
    "            cache = [l.get_empty_cache(x.shape[0], x.device) for l in self.layers]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        new_cache = []\n",
    "\n",
    "        for l, c in zip(self.layers, cache):\n",
    "            x, c = l(x, attn_cache=c)\n",
    "            new_cache.append(c)\n",
    "\n",
    "        x = self.final_proj(x)\n",
    "        return x, new_cache\n",
    "\n",
    "def test_transformer():\n",
    "\n",
    "    def test_run():\n",
    "        transformer = Transformer(16, 4, 32, 64, 4)\n",
    "        x = torch.tensor([[1, 2, 3]])\n",
    "        transformer(x)\n",
    "\n",
    "    def test_device():\n",
    "        transformer = Transformer(16, 4, 32, 64, 4)\n",
    "        x = torch.tensor([[1, 2, 3]]).to(torch.device(\"cpu\"))\n",
    "        transformer.to(torch.device(\"cpu\"))\n",
    "        transformer(x)\n",
    "\n",
    "    test_run()\n",
    "    test_device()\n",
    "\n",
    "test_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1707082247258,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "iZwmS02YLdcC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_recursive(n_first, vocab_size, next_prob):\n",
    "    assert 0 < vocab_size\n",
    "    initial = np.random.randint(0, vocab_size, n_first)\n",
    "    coeffs = np.random.randint(0, vocab_size, n_first)\n",
    "\n",
    "    return initial, coeffs, vocab_size, next_prob\n",
    "\n",
    "class SeqGen:\n",
    "    \"\"\"\n",
    "    For generating recurrent sequences with stochastically repeating terms.\n",
    "    \"\"\"\n",
    "    def __init__(self, initial, coeffs, size, next_prob):\n",
    "        assert len(coeffs) == len(initial)\n",
    "        self.initial = initial\n",
    "        self.coeffs = coeffs\n",
    "        self.size = size\n",
    "        self.next_prob = next_prob\n",
    "\n",
    "        self.current = initial\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if np.random.random() < self.next_prob:\n",
    "          new = self.current[-1] + 1\n",
    "        else:\n",
    "          new = (self.current @ self.coeffs)\n",
    "\n",
    "        new %= self.size\n",
    "        self.current = np.append(self.current, new)[1:]\n",
    "\n",
    "        return new\n",
    "\n",
    "    def __key(self):\n",
    "        return (tuple(self.initial), tuple(self.coeffs), self.size, self.next_prob)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.__key())\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, SeqGen):\n",
    "            return self.__key() == other.__key()\n",
    "\n",
    "\n",
    "def generate_dataset(gen_factory, seq_len, num_entries, exclude = []):\n",
    "    \"\"\"\n",
    "    For generating datasets with num_entries elements each\n",
    "    of length seq_len.\n",
    "\n",
    "      gen_factory is a procedure that returns\n",
    "        instance of SeqGen when called.\n",
    "\n",
    "      seq_len is the length of the sequence to generate.\n",
    "\n",
    "      num_entries is the number of sequences to generate.\n",
    "\n",
    "      exclude is the set of sequences that aren't to be used in training\n",
    "    \"\"\"\n",
    "    entries = []\n",
    "    generators = []\n",
    "    for e in range(num_entries):\n",
    "        while True:\n",
    "          seq_gen = gen_factory()\n",
    "          if seq_gen in exclude:\n",
    "              continue\n",
    "\n",
    "          seq = []\n",
    "          for s in range(seq_len + 1):\n",
    "              seq.append(next(seq_gen))\n",
    "\n",
    "          break\n",
    "\n",
    "        generators.append(seq_gen)\n",
    "        entries.append(seq)\n",
    "    data = torch.tensor(entries, dtype=torch.long)\n",
    "    x = data[:, :seq_len]\n",
    "    y = data[:, 1:]       # we predict next token\n",
    "    return torch.utils.data.TensorDataset(x, y), set(generators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707082247577,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "vyVN_OZWLdcC"
   },
   "outputs": [],
   "source": [
    "def example_generator(gen):\n",
    "    \"\"\"\n",
    "      A procedure that returns a representation of\n",
    "      a single data entrance.\n",
    "    \"\"\"\n",
    "    def example_gen():\n",
    "        return SeqGen(*gen())\n",
    "    return example_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 8721,
     "status": "ok",
     "timestamp": 1707082256297,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "pCRQKzkTLdcC"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "SEQ_LEN = 64\n",
    "\n",
    "\n",
    "VOCAB_SIZE = 7\n",
    "NEXT_PROB = .1\n",
    "INITIAL = 2\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "#DEVICE = torch.device(\"cpu\")\n",
    "PERM_EXAMPLE_GENERATOR = example_generator(lambda: generate_recursive(INITIAL, VOCAB_SIZE, NEXT_PROB))\n",
    "\n",
    "\n",
    "TEST_DATASET, generators = generate_dataset(\n",
    "    gen_factory=PERM_EXAMPLE_GENERATOR, seq_len=SEQ_LEN, num_entries=1000)\n",
    "TRAIN_DATASET, _ = generate_dataset(\n",
    "    gen_factory=PERM_EXAMPLE_GENERATOR, seq_len=SEQ_LEN, num_entries=10000, exclude=generators)\n",
    "\n",
    "\n",
    "TRAIN_LOADER = torch.utils.data.DataLoader(\n",
    "    TRAIN_DATASET, batch_size=BATCH_SIZE)\n",
    "TEST_LOADER = torch.utils.data.DataLoader(TEST_DATASET, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337315,
     "status": "ok",
     "timestamp": 1707082598367,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "aklEe_nfLdcE",
    "outputId": "1d369f69-62c5-4066-bec0-8bf9c2c1a95b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Avg eval accuracy 0.14079686999320984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:39,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Avg eval accuracy 0.47151562571525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:39,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Avg eval accuracy 0.6825312376022339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:39,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: Avg eval accuracy 0.747671902179718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:40,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: Avg eval accuracy 0.775515615940094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:39,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: Avg eval accuracy 0.7870156168937683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:39,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: Avg eval accuracy 0.7970156073570251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:39,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6: Avg eval accuracy 0.8039844036102295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:39,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7: Avg eval accuracy 0.8125468492507935\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import functools\n",
    "\n",
    "\n",
    "@torch.no_grad\n",
    "def eval_acc(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader):\n",
    "    model.eval()\n",
    "    sum_acc = 0\n",
    "    num_examples = 0\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        model_out, _ = model(x)\n",
    "\n",
    "        acc = (torch.argmax(model_out, dim=-1) == y).to(torch.float32).sum()\n",
    "        sum_acc += acc\n",
    "        num_examples += model_out.shape[0] * model_out.shape[1]\n",
    "\n",
    "    return sum_acc / num_examples\n",
    "\n",
    "\n",
    "def eval_fn(step, model, dataloader):\n",
    "    acc = eval_acc(model, dataloader)\n",
    "    print(f\"{step}: Avg eval accuracy {acc}\")\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    eval_fn,\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(8):\n",
    "        if epoch == 0:\n",
    "            eval_fn(epoch, model)\n",
    "\n",
    "        for i, (x, y) in tqdm(enumerate(dataloader)):\n",
    "            model.zero_grad()\n",
    "\n",
    "            res, _ = model(x)\n",
    "\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(res.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        eval_fn(epoch, model)\n",
    "\n",
    "\n",
    "model = Transformer(\n",
    "    vocab_size=VOCAB_SIZE, n_layers=4, hidden_dim=64, ff_dim=128, num_heads=4\n",
    ")\n",
    "model.to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    dataloader=TRAIN_LOADER,\n",
    "    eval_fn=functools.partial(\n",
    "        eval_fn,\n",
    "        dataloader=TEST_LOADER,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1707082715424,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "kuTzGF-aLdcE"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def token_choice_greedy(model_logits: ModelLT):\n",
    "    assert len(model_logits.shape) == 3 # [BATCH, SEQ, VOCAB_SIZE]\n",
    "    return torch.argmax(model_logits[:, [-1], :], dim=-1)\n",
    "\n",
    "@torch.no_grad\n",
    "def generate_naive(model: torch.nn.Module, input: TokensT, gen_length: int, token_choice = token_choice_greedy) -> TokensT:\n",
    "    \"\"\"\n",
    "    Given an input of shape [BATCH, SEQ_LEN] uses the model to generate\n",
    "    an output of shape [BATCH, gen_length] so that the output is the model\n",
    "    response to the input according to token_choice strategy.\n",
    "    \"\"\"\n",
    "    assert len(input.shape) == 2 # BATCH, SEQ\n",
    "    model.eval()\n",
    "    input = input.to(DEVICE)\n",
    "    output = []\n",
    "    for _ in range(gen_length):\n",
    "        model_output, _ = model(input)\n",
    "        next_tokens = token_choice(model_output)\n",
    "        output.append(next_tokens.cpu())\n",
    "        input = torch.concat([input, next_tokens], dim=-1)\n",
    "\n",
    "    return torch.concat(output, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3796,
     "status": "ok",
     "timestamp": 1707082721041,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "bhQHSkQcLdcF"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def get_dist_after_with_temp_and_topp(\n",
    "    model_logits: ModelLT, top_p: float, t: float\n",
    ") -> ModelLT:\n",
    "    \"\"\"\n",
    "    Allows to alter softmax temperature and sample using most probable elements that constitute to roughly top_p\n",
    "    probability mass of the distribution.\n",
    "\n",
    "    Given the output of the model before softmax (model_logits of shape [BATCH, SEQ, VOCAB_SIZE]),\n",
    "    computes the softmax with temperature t (softmax(model_logits / t, dim=-1))\n",
    "    to get the probability distribution prob (of shape [BATCH, SEQ, VOCAB_SIZE]) on the next token.\n",
    "    Then for each b, s orders elements of prob[b, s] in non-ascending order\n",
    "    and selects a prefix (pref[b, s])) of them such that the cummulative probability of sampling an element from this\n",
    "    prefix is < top_p but after adding the next element it is >= top_p.\n",
    "    Then it adds the next element to pref[b, s] (now the cummulative probability is >= top_p),\n",
    "    sets the probability of remaining elements to 0.0, and rescales the probability distribution.\n",
    "    The implementation is vectorized.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(model_logits.shape) == 3\n",
    "\n",
    "    y = torch.nn.functional.softmax(model_logits / t, dim=-1)\n",
    "\n",
    "    sorted_probs, sorted_indices = torch.sort(y, descending=True)\n",
    "    cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "\n",
    "    cutoff_indices = cumulative_probs  < top_p\n",
    "    cutoff_indices[..., 1:] = cutoff_indices[..., :-1].clone()\n",
    "    if not cutoff_indices.any(dim=-1).all():\n",
    "        cutoff_indices[..., 0] = True\n",
    "    sorted_probs.masked_fill_(~cutoff_indices, 0)\n",
    "\n",
    "    original_order_probs = torch.zeros_like(sorted_probs)\n",
    "    original_order_probs.scatter_(-1, sorted_indices, sorted_probs)\n",
    "    result = original_order_probs / original_order_probs.sum(dim=-1, keepdim=True)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "@torch.no_grad\n",
    "def token_choice_adv(model_logits: ModelLT, top_p: float, t: float) -> ModelLT:\n",
    "    probs = get_dist_after_with_temp_and_topp(\n",
    "        model_logits=model_logits[:, [-1], :], top_p=top_p, t=t\n",
    "    )\n",
    "    dist = torch.distributions.Categorical(probs=probs)\n",
    "    return dist.sample()\n",
    "\n",
    "\n",
    "##### TESTS START #####\n",
    "@torch.no_grad\n",
    "def test_nucleus():\n",
    "    def test_dist_topp():\n",
    "        # equal probs\n",
    "        res = get_dist_after_with_temp_and_topp(\n",
    "            torch.tensor([[[1.0, 1.0, 1.0]]]), top_p=1.0, t=1.0\n",
    "        )\n",
    "        assert torch.abs(res - torch.tensor([1 / 3, 1 / 3, 1 / 3])).sum() <= 1e-4\n",
    "\n",
    "        # non-equal probs\n",
    "\n",
    "        res = get_dist_after_with_temp_and_topp(\n",
    "            torch.tensor([[[2.0, 3.0, 1.0]]]), top_p=0.0, t=1.0\n",
    "        )\n",
    "        assert torch.abs(res - torch.tensor([0.0, 1.0, 0.0])).sum() <= 1e-4\n",
    "\n",
    "        res = get_dist_after_with_temp_and_topp(\n",
    "            torch.tensor([[[2.0, 3.0, 1.0]]]), top_p=0.6, t=1.0\n",
    "        )\n",
    "        assert torch.abs(res - torch.tensor([0.0, 1.0, 0.0])).sum() <= 1e-4\n",
    "\n",
    "        res = get_dist_after_with_temp_and_topp(\n",
    "            torch.tensor([[[1.0, 3.0, 2.0]]]), top_p=0.7, t=1.0\n",
    "        )\n",
    "        assert torch.abs(res - torch.tensor([0.0, 0.7311, 0.2689])).sum() <= 1e-2\n",
    "\n",
    "        res = get_dist_after_with_temp_and_topp(\n",
    "            torch.tensor([[[1.0, 3.0, 2.0]]]), top_p=1.0, t=1.0\n",
    "        )\n",
    "        assert torch.abs(res - torch.tensor([0.0900, 0.6652, 0.2447])).sum() <= 1e-2\n",
    "\n",
    "    def test_temperature():\n",
    "        res = get_dist_after_with_temp_and_topp(\n",
    "            torch.tensor([[[1.0, 1.0, 1.0]]]), top_p=1.0, t=3.0\n",
    "        )\n",
    "        assert torch.abs(res - torch.tensor([1 / 3, 1 / 3, 1 / 3])).sum() <= 1e-4\n",
    "\n",
    "        res = get_dist_after_with_temp_and_topp(\n",
    "            torch.tensor([[[1.0, 3.0, 2.0]]]), top_p=1.0, t=3.0\n",
    "        )\n",
    "        assert torch.abs(res - torch.tensor([0.2302, 0.4484, 0.3213])).sum() <= 1e-2\n",
    "\n",
    "        res = get_dist_after_with_temp_and_topp(\n",
    "            torch.tensor([[[1.0, 3.0, 2.0]]]), top_p=1.0, t=1 / 3\n",
    "        )\n",
    "        assert torch.abs(res - torch.tensor([0.0024, 0.9503, 0.0473])).sum() <= 1e-2\n",
    "\n",
    "        res = get_dist_after_with_temp_and_topp(\n",
    "            torch.tensor([[[1.0, 3.0, 2.0]]]), top_p=0.94, t=1 / 3\n",
    "        )\n",
    "        assert torch.abs(res - torch.tensor([0.0, 1.0, 0.0])).sum() <= 1e-4\n",
    "\n",
    "    def test_batching():\n",
    "        res = get_dist_after_with_temp_and_topp(\n",
    "            torch.tensor(\n",
    "                [[[1.0, 3.0, 2.0], [1.0, 4.0, 8.0]], [[8.0, 4.0, 1.0], [3.0, 1.0, 2.0]]]\n",
    "            ),\n",
    "            top_p=0.7,\n",
    "            t=1.0,\n",
    "        )\n",
    "        assert (\n",
    "            torch.abs(\n",
    "                res\n",
    "                - torch.tensor(\n",
    "                    [\n",
    "                        [[0.0, 0.7311, 0.2689], [0.0, 0.0, 1.0]],\n",
    "                        [[1.0, 0.0, 0.0], [0.7311, 0.0, 0.2689]],\n",
    "                    ]\n",
    "                )\n",
    "            ).sum()\n",
    "            <= 1e-2\n",
    "        )\n",
    "\n",
    "    test_dist_topp()\n",
    "    test_temperature()\n",
    "    test_batching()\n",
    "\n",
    "@torch.no_grad\n",
    "def test_token_choice_adv(model):\n",
    "    def test_equivalence():\n",
    "        batch = 3\n",
    "        for i in range(1, 20):\n",
    "            input = torch.randint(0, VOCAB_SIZE, (batch, SEQ_LEN - i))\n",
    "            output_naive_gen = generate_naive(\n",
    "                model, input, i, token_choice=token_choice_greedy\n",
    "            )\n",
    "            output_cache_gen = generate_naive(\n",
    "                model, input, i, functools.partial(token_choice_adv, top_p=0.0, t=1.0)\n",
    "            )\n",
    "            assert (output_naive_gen == output_cache_gen).to(torch.int32).sum() == batch * i\n",
    "\n",
    "    test_equivalence()\n",
    "\n",
    "\n",
    "test_nucleus()\n",
    "test_token_choice_adv(model)\n",
    "#####  TESTS END  #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4NJuSAwLdcF"
   },
   "source": [
    "You can check responses of your model using the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3337,
     "status": "ok",
     "timestamp": 1707082728418,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "vvjwfaDJLdcF",
    "outputId": "3e78819a-2817-44cf-91c2-104da9262339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  tensor([[2, 2]])\n",
      "checking top_p\n",
      "tensor([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
      "tensor([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
      "tensor([[2, 1, 6, 3, 4, 2, 3, 6, 2, 4, 6, 5, 4, 5, 5, 6, 1, 2, 3, 6, 2, 4, 6, 5,\n",
      "         4, 1, 5, 3, 1, 2, 3, 6, 2, 4, 6, 5, 4, 1, 5, 3, 1, 2, 3, 6, 2, 4, 6, 5,\n",
      "         4, 1, 5, 3, 1, 2, 3, 6, 2, 4, 6, 5, 4, 1]])\n",
      "checking temperature\n",
      "tensor([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
      "tensor([[2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]])\n",
      "tensor([[3, 3, 6, 3, 1, 2, 3, 3, 4, 5, 1, 3, 2, 6, 4, 5, 1, 3, 2, 6, 4, 5, 1, 3,\n",
      "         2, 6, 4, 5, 1, 3, 2, 6, 4, 5, 1, 3, 2, 6, 4, 5, 1, 3, 2, 6, 4, 5, 1, 3,\n",
      "         2, 6, 4, 5, 1, 3, 2, 6, 4, 5, 1, 3, 2, 6]])\n",
      "checking sequence length\n",
      "tensor([[4, 5, 6, 6, 0, 6, 1, 5, 3, 2, 1, 1, 0, 1, 6, 2, 4, 5, 6, 6, 0, 6, 1, 5,\n",
      "         3, 2, 1, 1, 0, 1, 6, 2, 4, 5, 6, 6, 0, 6, 1, 5, 3, 2, 1, 1, 0, 1, 6, 2,\n",
      "         4, 5, 6, 6, 0, 6, 1, 5, 3, 2, 1, 1, 0, 1]])\n",
      "tensor([[4, 2, 3, 3, 3, 4, 6, 6, 0, 5, 1, 6, 6, 2, 4, 2, 0, 4, 5, 2, 2, 3, 6, 3,\n",
      "         0, 6, 4, 3, 3, 1, 2, 1, 0, 2, 6, 1, 1, 5, 3, 5, 0, 3, 2, 5, 5, 4, 1, 2,\n",
      "         1, 3, 3, 4, 6, 0, 1, 2, 1, 3, 3, 4]])\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4,\n",
      "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 4, 4, 4]])\n",
      "tensor([[2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         4, 4, 4, 4, 4, 4, 4, 4]])\n"
     ]
    }
   ],
   "source": [
    "#input_data = torch.ones((1, SEQ_LEN-10), dtype=int) * 2\n",
    "\n",
    "input_data = torch.ones((1, INITIAL), dtype=int) * 2\n",
    "print(\"Input data: \", input_data)\n",
    "print(\"checking top_p\")\n",
    "print(generate_naive(model=model, input=input_data, gen_length=SEQ_LEN - input_data.shape[-1], token_choice=functools.partial(token_choice_adv, top_p=0, t=0.5)))\n",
    "print(generate_naive(model=model, input=input_data, gen_length=SEQ_LEN - input_data.shape[-1], token_choice=functools.partial(token_choice_adv, top_p=0.5, t=0.5)))\n",
    "print(generate_naive(model=model, input=input_data, gen_length=SEQ_LEN - input_data.shape[-1], token_choice=functools.partial(token_choice_adv, top_p=1, t=0.5)))\n",
    "print(\"checking temperature\")\n",
    "print(generate_naive(model=model, input=input_data, gen_length=SEQ_LEN - input_data.shape[-1], token_choice=functools.partial(token_choice_adv, top_p=0.5, t=0.1)))\n",
    "print(generate_naive(model=model, input=input_data, gen_length=SEQ_LEN - input_data.shape[-1], token_choice=functools.partial(token_choice_adv, top_p=0.5, t=1.0)))\n",
    "print(generate_naive(model=model, input=input_data, gen_length=SEQ_LEN - input_data.shape[-1], token_choice=functools.partial(token_choice_adv, top_p=0.5, t=1.9)))\n",
    "print('checking sequence length')\n",
    "put_data = torch.ones((1, INITIAL), dtype=int) * 2\n",
    "print(generate_naive(model=model, input=input_data, gen_length=SEQ_LEN - input_data.shape[-1], token_choice=functools.partial(token_choice_adv, top_p=0.5, t=1)))\n",
    "input_data = torch.ones((1, INITIAL * 2), dtype=int) * 2\n",
    "print(generate_naive(model=model, input=input_data, gen_length=SEQ_LEN - input_data.shape[-1], token_choice=functools.partial(token_choice_adv, top_p=0.5, t=1)))\n",
    "input_data = torch.ones((1, INITIAL * 4), dtype=int) * 2\n",
    "print(generate_naive(model=model, input=input_data, gen_length=SEQ_LEN - input_data.shape[-1], token_choice=functools.partial(token_choice_adv, top_p=0.5, t=1)))\n",
    "input_data = torch.ones((1, INITIAL * 16), dtype=int) * 2\n",
    "print(generate_naive(model=model, input=input_data, gen_length=SEQ_LEN - input_data.shape[-1], token_choice=functools.partial(token_choice_adv, top_p=0.5, t=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "executionInfo": {
     "elapsed": 2339,
     "status": "ok",
     "timestamp": 1707082861870,
     "user": {
      "displayName": "Szymon Pobłocki",
      "userId": "17778215756659128917"
     },
     "user_tz": -60
    },
    "id": "k2tl_OULLdcG",
    "outputId": "20193683-e0d0-4382-d1e6-c025f867c68e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1852464  0.20567909 0.27140924 0.44335938 0.5715144  0.6934345\n",
      " 0.7491737  0.78305286 0.81715745 0.83436    0.8359375  0.8289513\n",
      " 0.8564453  0.8367638  0.8416466  0.86335635 0.8626803  0.85990083\n",
      " 0.8621544  0.84405047 0.8487079  0.8534405  0.85178787 0.8762019\n",
      " 0.8544922  0.8528395  0.87116885 0.8538161  0.86816406 0.8642578\n",
      " 0.86763823 0.8716196  0.84397537 0.84765625 0.86035156 0.84277344\n",
      " 0.86545974 0.85922474 0.85208833 0.8705679  0.85877407 0.8686148\n",
      " 0.8756761  0.87740386 0.8528395  0.85621995 0.8559195  0.8630559\n",
      " 0.86748797 0.8780048  0.8728966  0.85554385 0.85682094 0.87409854\n",
      " 0.86042666 0.8691406  0.8665114  0.8798077  0.8927284  0.8727464\n",
      " 0.8627554  0.85329026 0.8601262  0.86102766]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "@torch.no_grad\n",
    "def calc_per_token_acc(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader):\n",
    "    token_accuracies = []\n",
    "    for x, y in data_loader:\n",
    "        res, _ = model(x)\n",
    "        _, predicted = torch.max(res, dim=-1)\n",
    "        correct = (predicted == y)\n",
    "\n",
    "        batch_accuracies = correct.float().mean(dim=0).cpu().numpy()\n",
    "        token_accuracies.append(batch_accuracies)\n",
    "\n",
    "    per_token_acc = np.mean(token_accuracies, axis=0)\n",
    "    print(per_token_acc)\n",
    "    return per_token_acc\n",
    "\n",
    "per_token_acc = calc_per_token_acc(model, TEST_LOADER)\n",
    "plt.plot(np.arange(per_token_acc.shape[0]), per_token_acc)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Ru5HzBx_7miy",
    "WFG6KE3GLdb7",
    "FKbxi2SALdb9",
    "Lwc1m-JoLdcA",
    "yx_SedLaLdcC",
    "VwvSkw9rLdcE"
   ],
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/mim-uw/dnn-2023-24/blob/master/docs/hw3-transformer-student.ipynb",
     "timestamp": 1705238063273
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
